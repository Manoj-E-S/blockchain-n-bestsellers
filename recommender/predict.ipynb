{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../recommender/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = CudaUtils.get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_encoder, isbn_encoder = EncoderUtils.load_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Books: 58478\n",
      "Number of Users: 54426\n"
     ]
    }
   ],
   "source": [
    "n_books = len(isbn_encoder.classes_)\n",
    "n_users = len(userid_encoder.classes_)\n",
    "\n",
    "print(f\"Number of Books: {n_books}\")\n",
    "print(f\"Number of Users: {n_users}\")\n",
    "\n",
    "# model = RatingsPredictorMLP(n_books, n_users).to(device)\n",
    "# model.load_state_dict(torch.load('./models/model_cross_val_3folds.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate default_user_index - an encoded userid that represents the \"average user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2894,  0.4537,  1.5684,  ...,  0.0081, -2.0207,  0.7572],\n",
       "        [-0.2934,  0.9662, -0.3722,  ..., -1.0948,  0.1260,  1.9815],\n",
       "        [ 0.7165,  0.9545, -1.2309,  ..., -0.0577,  0.2474,  0.9960],\n",
       "        ...,\n",
       "        [ 0.0465,  1.1541, -0.1318,  ...,  0.6238,  0.5805, -1.0340],\n",
       "        [ 1.0899, -0.2101,  0.9566,  ...,  0.3194,  1.2263, -1.3410],\n",
       "        [-1.4835,  0.1813, -0.6118,  ...,  0.1732, -0.2838, -0.1646]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embeddings = model.user_embed.weight.data\n",
    "user_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0075,  0.0054,  0.0143, -0.0121,  0.0136, -0.0145,  0.0130, -0.0074,\n",
       "        -0.0053,  0.0158, -0.0071,  0.0145,  0.0087, -0.0054,  0.0181, -0.0141,\n",
       "         0.0091,  0.0139, -0.0219,  0.0209, -0.0081, -0.0180, -0.0102,  0.0099,\n",
       "        -0.0028, -0.0216,  0.0066,  0.0123,  0.0169, -0.0077,  0.0114,  0.0030])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_user_embedding = torch.mean(user_embeddings, dim=0)\n",
    "average_user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0634,  0.0805,  0.1056,  ..., -0.0116,  0.2423, -0.1365])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim = F.cosine_similarity(user_embeddings, average_user_embedding.unsqueeze(0))\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A default user is one who's ratings are similar (cos_sim) to the avg latent feature vector of all users in the dataset. The first time user can be approximated as an average user with reliable accuracy (as all humans are alike at a surface level). Later, after she/he starts rating books her/his uniqueness will be assessed and addressed by the model. Essentially all users start out as \"the average reader\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35553"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_user_idx = torch.argmax(cos_sim).item()\n",
    "default_user_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35553"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the default_user_idx is properly calculated\n",
    "user_id = userid_encoder.classes_[default_user_idx]\n",
    "userid_encoder.transform([user_id])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend top 10 books to the user, based on predicted ratings for all books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = default_user_idx if user_id not in userid_encoder.classes_ else userid_encoder.transform([user_id])[0]\n",
    "user_tensor = torch.tensor([user_index] * len(isbn_encoder.classes_), dtype=torch.long).to(device)\n",
    "book_tensor = torch.arange(len(isbn_encoder.classes_), dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rating   isbn\n",
      "305877     5.0    399\n",
      "305879     5.0   7068\n",
      "305884     5.0   8775\n",
      "305886     5.0   8851\n",
      "305887     5.0   8883\n",
      "...        ...    ...\n",
      "306105     5.0  52823\n",
      "306106     5.0  52825\n",
      "306107     5.0  52831\n",
      "306108     5.0  52835\n",
      "306109     5.0  53110\n",
      "\n",
      "[118 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False, False, False,  True,\n",
       "        False, False,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(user_tensor, book_tensor)\n",
    "\n",
    "ratings_df = DfUtils.get_ratings_df('./main_dataset/updated_ratings.csv')\n",
    "expected = ratings_df.loc[ratings_df[\"user_id\"] == user_index, [\"rating\", \"isbn\"]]\n",
    "print(expected)\n",
    "\n",
    "predictions_filtered = predictions[expected[\"isbn\"].values]\n",
    "x = ( predictions_filtered.flatten() - torch.tensor(expected[\"rating\"].values).to(device) ).abs() > 0.26\n",
    "x\n",
    "# predictions_filtered.view(-1) and predictions_filtered.flatten() are functionally the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold for the model's predictions is ~0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([4.9463, 4.9461, 4.9458,  ..., 4.5933, 4.5868, 4.5769]),\n",
      "indices=tensor([25753, 32809, 54501,  ..., 39340, 33206, 46078]))\n",
      "\n",
      "tensor([25753, 32809, 54501, 29826, 23189, 36665, 20530,   833, 14083, 23190])\n",
      "\n",
      "tensor([25753, 32809, 54501, 29826, 23189, 36665, 20530,   833, 14083, 23190])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predictions.view(-1).sort(descending=True), end=\"\\n\\n\")\n",
    "print(predictions.view(-1).sort(descending=True)[1][:10], end=\"\\n\\n\")\n",
    "print(predictions.view(-1).argsort(descending=True)[:10], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25753, 32809, 54501, 29826, 23189, 36665, 20530,   833, 14083, 23190])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_books = predictions.view(-1).argsort(descending=True)[:10]\n",
    "top_n_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0446310786', '0553205587', '1575450607', '0451457552',\n",
       "       '0439139597', '0618002235', '039480029X', '0060194995',\n",
       "       '0373257988', '0439139600'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_books = isbn_encoder.inverse_transform(top_n_books.numpy())\n",
    "recommended_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user(user_id, model, book_encoder, userid_encoder, default_user_index):\n",
    "    user_index = default_user_index if user_id not in userid_encoder.classes_ else userid_encoder.transform([user_id])[0]\n",
    "    user_tensor = torch.tensor([user_index] * len(book_encoder.classes_), dtype=torch.long)\n",
    "    book_indices = torch.arange(len(book_encoder.classes_), dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_tensor, book_indices)\n",
    "    \n",
    "    top_n_books = predictions.view(-1).argsort(descending=True)[:10]\n",
    "    recommended_books = book_encoder.inverse_transform(top_n_books.numpy())\n",
    "    \n",
    "    return recommended_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
